{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangyf5996/tensorflow_learning/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aMmFguvnyTD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###\n",
        "# 样例数据是针对mnist，有一些封装好的函数，如果使用自己的数据，\n",
        "# 数据的读取可以参考 https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10\n",
        "###\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import slim\n",
        "from tensorflow import keras\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "tf.app.flags.DEFINE_integer('image_height', 28, 'the height of image')\n",
        "tf.app.flags.DEFINE_integer('image_width', 28, 'the width of image')\n",
        "tf.app.flags.DEFINE_integer('batch_size', 128, 'Number of images to process in a batch')\n",
        "TRAIN_EXAMPLES_NUM = 55000\n",
        "VALIDATION_EXAMPLES_NUM = 5000\n",
        "TEST_EXAMPLES_NUM = 10000\n",
        "\n",
        "#STEP1：输入数据的解析和预处理\n",
        "def parse_data(example_proto):\n",
        "    features = {'img_raw': tf.FixedLenFeature([], tf.string, ''),\n",
        "                'label': tf.FixedLenFeature([], tf.int64, 0)}\n",
        "    parsed_features = tf.parse_single_example(example_proto, features)\n",
        "    image = tf.decode_raw(parsed_features['img_raw'], tf.uint8)\n",
        "    label = tf.cast(parsed_features['label'], tf.int64)\n",
        "    image = tf.reshape(image, [FLAGS.image_height, FLAGS.image_width, 1])\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image, label\n",
        "  \n",
        "def read_mnist_tfrecords(filename_queue):\n",
        "    reader = tf.TFRecordReader()\n",
        "    _, serialized_example = reader.read(filename_queue)\n",
        "\n",
        "    features = tf.parse_single_example(serialized_example, features={\n",
        "        'img_raw': tf.FixedLenFeature([], tf.string, ''),\n",
        "        'label': tf.FixedLenFeature([], tf.int64, 0)\n",
        "    })\n",
        "    image = tf.decode_raw(features['img_raw'], tf.uint8)\n",
        "    label = tf.cast(features['label'], tf.int64)\n",
        "    image = tf.reshape(image, [FLAGS.image_height, FLAGS.image_width, 1])\n",
        "    return image, label\n",
        "  \n",
        "def inputs(filenames, examples_num, batch_size, shuffle):\n",
        "    for f in filenames:\n",
        "        if not tf.gfile.Exists(f):\n",
        "            raise ValueError('Failed to find file: ' + f)\n",
        "    with tf.name_scope('inputs'):\n",
        "        filename_queue = tf.train.string_input_producer(filenames)\n",
        "        image, label = read_mnist_tfrecords(filename_queue)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        min_fraction_of_examples_in_queue = 0.4\n",
        "        min_queue_examples = int(min_fraction_of_examples_in_queue * examples_num)\n",
        "        num_process_threads = 16\n",
        "        if shuffle:\n",
        "            images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size,\n",
        "                                                    num_threads=num_process_threads,\n",
        "                                                    capacity=min_queue_examples + batch_size * 3,\n",
        "                                                    min_after_dequeue=min_queue_examples)\n",
        "        else:\n",
        "            images, labels = tf.train.batch([image, label], batch_size=batch_size,\n",
        "                                            num_threads=num_process_threads,\n",
        "                                            capacity=min_queue_examples + batch_size * 3)\n",
        "        return images, labels\n",
        "\n",
        "      \n",
        "#STEP2：定义模型\n",
        "def inference(images, training):\n",
        "    with tf.variable_scope('conv1'):\n",
        "        conv1 = tf.layers.conv2d(inputs=images,\n",
        "                                 filters=32,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding='same',\n",
        "                                 activation=tf.nn.relu)\n",
        " \n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)      # 14*14*32\n",
        " \n",
        "    with tf.variable_scope('conv2'):\n",
        "        conv2 = tf.layers.conv2d(inputs=pool1,\n",
        "                                 filters=64,\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding='same',\n",
        "                                 activation=tf.nn.relu)\n",
        " \n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)      # 7*7*64\n",
        " \n",
        "    with tf.variable_scope('fc1'):\n",
        "        pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
        "        fc1 = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "        dropout1 = tf.layers.dropout(inputs=fc1, rate=0.4, training=training)\n",
        " \n",
        "    with tf.variable_scope('logits'):\n",
        "        logits = tf.layers.dense(inputs=dropout1, units=10)     # 使用该值计算交叉熵损失\n",
        "        predict = tf.nn.softmax(logits)\n",
        " \n",
        "    return logits, predict\n",
        "\n",
        "\n",
        "#STEP3:定义计算损失并定义训练操作\n",
        "def loss(logits, labels):\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='cross_entropy')\n",
        "    cross_entropy_loss = tf.reduce_mean(cross_entropy)\n",
        "    return cross_entropy_loss\n",
        " \n",
        " \n",
        "def train(total_loss, global_step):\n",
        "    num_batches_per_epoch = TRAIN_EXAMPLES_NUM / FLAGS.batch_size\n",
        "    decay_steps = int(num_batches_per_epoch * 10)\n",
        " \n",
        "    # Decay the learning rate exponentially based on the number of steps.\n",
        "    lr = tf.train.exponential_decay(learning_rate=0.001,\n",
        "                                    global_step=global_step,\n",
        "                                    decay_steps=decay_steps,\n",
        "                                    decay_rate=0.1,\n",
        "                                    staircase=True)\n",
        " \n",
        "    # opt = tf.train.GradientDescentOptimizer(lr)\n",
        "    # opt = tf.train.MomentumOptimizer(learning_rate=0.001, momentum=0.99)\n",
        "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "    grad = opt.compute_gradients(total_loss)\n",
        "    apply_grad_op = opt.apply_gradients(grad, global_step)\n",
        " \n",
        "    return apply_grad_op\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "#STEP5:模型验证\n",
        "def eval_once(saver, top_k_op):\n",
        "    with tf.Session() as sess:\n",
        "        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
        "        if ckpt and ckpt.model_checkpoint_path:\n",
        "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
        "        else:\n",
        "            print('no checkpoint file')\n",
        "            return\n",
        " \n",
        "        coord = tf.train.Coordinator()\n",
        "        try:\n",
        "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        " \n",
        "            iter_per_epoch = int(math.ceil(mnist.VALIDATION_EXAMPLES_NUM / FLAGS.batch_size))\n",
        " \n",
        "            total_sample = iter_per_epoch * FLAGS.batch_size\n",
        "            correct_predict = 0\n",
        "            step = 0\n",
        " \n",
        "            while step < iter_per_epoch and not coord.should_stop():\n",
        "                predict = sess.run(top_k_op)\n",
        "                correct_predict += np.sum(predict)\n",
        "                step += 1\n",
        " \n",
        "            precision = correct_predict / total_sample\n",
        "            print('step: {}, model: {}, precision: {}'.format(global_step, ckpt.model_checkpoint_path, precision))\n",
        " \n",
        "        except Exception as e:\n",
        "            print('exception: ', e)\n",
        "            coord.request_stop(e)\n",
        "        finally:\n",
        "            coord.request_stop()\n",
        "        coord.join(threads)\n",
        " \n",
        " \n",
        "def evaluation():\n",
        "    images, labels = mnist.inputs(['./validation_img.tfrecords'], mnist.VALIDATION_EXAMPLES_NUM,\n",
        "                                  batch_size=FLAGS.batch_size, shuffle=False)\n",
        "    logits, pred = mnist.inference(images, training=False)\n",
        "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
        " \n",
        "    saver = tf.train.Saver()\n",
        " \n",
        "    while True:\n",
        "        eval_once(saver, top_k_op)\n",
        "        if FLAGS.run_once:\n",
        "            break\n",
        "        time.sleep(FLAGS.eval_interval_secs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}